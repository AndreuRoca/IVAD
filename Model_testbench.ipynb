{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testbench\n",
    "\n",
    "\n",
    "In this jupyter notebook I have all the model tests documented. Written in Python3 and SKlearn. Don't \"run all\" this notebook. It's computationally complex and can take a very long time to complete.\n",
    "\n",
    "Dependences: \\\n",
    "-Numpy  \\\n",
    "-Pandas \\\n",
    "-Matplotlib \\\n",
    "-ScyPy \\\n",
    "-Sklearn \\\n",
    "-Lightgbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier,NeighborhoodComponentsAnalysis, NearestCentroid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA, KernelPCA, IncrementalPCA\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "from scipy.fft import fft, ifft\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 12003)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"dataset_new_features.csv\")\n",
    "y=dataset.iloc[:,-1]\n",
    "X=dataset.iloc[:,:-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic classifications (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, penalty='none').fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2=LinearSVC(penalty='l2',random_state=0, tol=1e-5,max_iter=9000,C=1,loss='squared_hinge').fit(X_train,y_train)\n",
    "clf2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3416666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = KNeighborsClassifier(n_neighbors=7).fit(X_train, y_train)\n",
    "clf3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4083333333333333 1\n"
     ]
    }
   ],
   "source": [
    "sc=0\n",
    "iteration=0\n",
    "for neig in range(1,200):\n",
    "    clf3 = KNeighborsClassifier(n_neighbors=neig).fit(X_train, y_train)\n",
    "    if sc<clf3.score(X_test,y_test):\n",
    "        sc=clf3.score(X_test,y_test)\n",
    "        iteration=neig\n",
    "print (sc, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667 1\n"
     ]
    }
   ],
   "source": [
    "red5=PCA(.90)\n",
    "X_train_PCA=red5.fit_transform(X_train)\n",
    "X_test_PCA=red5.transform(X_test)\n",
    "sc=0\n",
    "iteration=0\n",
    "for neig in range(1,200):\n",
    "    clf3 = KNeighborsClassifier(n_neighbors=neig).fit(X_train_PCA, y_train)\n",
    "    if sc<clf3.score(X_test_PCA,y_test):\n",
    "        sc=clf3.score(X_test_PCA,y_test)\n",
    "        iteration=neig\n",
    "print (sc, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = LogisticRegression(random_state=0, max_iter=10000)\n",
    "params=([{'penalty': ['none'], 'solver': ['newton-cg', 'lbfgs', 'sag','saga']},\n",
    "        {'penalty': ['elasticnet'], 'solver': ['saga']},\n",
    "        {'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'sag','saga','liblinear']},\n",
    "        {'penalty': ['l1'], 'solver': ['liblinear', 'saga']},])\n",
    "gs=GridSearchCV(clf8,params).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4=LinearSVC(penalty='l2',random_state=0, tol=1e-5,max_iter=9000,C=1,loss='squared_hinge').fit(X_train,y_train)\n",
    "clf4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SVC(C=1, gamma=0.0001, random_state=1),\n",
       " {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       " 0.49642857142857144)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6 = SVC(random_state=1, kernel='rbf', C=80, gamma=0.0001).fit(X_train,y_train)\n",
    "clf6.score(X_test, y_test)\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "gs=GridSearchCV(clf6,param_grid).fit(X_train,y_train)\n",
    "gs.best_estimator_, gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SVC(C=40, gamma=0.0001, random_state=1),\n",
       " {'C': 40, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       " 0.4574999999999999)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "  {'C': [40,100,400], 'gamma': [0.001, 0.0001, 0.00001], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "gs2=GridSearchCV(clf6,param_grid).fit(X,y)\n",
    "gs2.best_estimator_, gs2.best_params_, gs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid3= [\n",
    "  {'C': [1,10,80,100,400,1000], 'loss': ['hinge','squared_hinge']},]\n",
    "gs3=GridSearchCV(LinearSVC(), param_grid3).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44166666666666665"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red=PCA(.90)\n",
    "X_train_PCA=red.fit_transform(X_train)\n",
    "X_test_PCA=red.transform(X_test)\n",
    "\n",
    "clf5 = SVC(random_state=1, kernel='rbf', C=80, gamma=0.0001).fit(X_train,y_train)\n",
    "clf5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SVC(C=40, gamma=1e-05, random_state=1), 0.4714285714285714)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red2=KernelPCA(.90)\n",
    "X_train_KPCA=red.fit_transform(X_train)\n",
    "X_test_KPCA=red.transform(X_test)\n",
    "param_grid = [{'C': [40,100,400], 'gamma': [0.001, 0.0001, 0.00001], 'kernel': ['rbf']},]\n",
    "gs4=GridSearchCV(clf5,param_grid).fit(X_train_KPCA,y_train)\n",
    "gs4.best_estimator_, gs4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SVC(C=100, gamma=1e-05),\n",
       " 0.46071428571428574,\n",
       " {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red4=PCA(.90)\n",
    "sc=StandardScaler()\n",
    "X_train_sc=sc.fit_transform(X_train)\n",
    "X_test_sc=sc.transform(X_test)\n",
    "X_train_PCA=red4.fit_transform(X_train_sc)\n",
    "X_test_PCA=red4.transform(X_test_sc)\n",
    "sc=StandardScaler()\n",
    "sc.fit_transform(X_train)\n",
    "sc.transform(X_test)\n",
    "clf6=SVC()\n",
    "param_grid = [{'C': [0.1, 40, 100, 400], 'gamma': [0.001, 0.0001, 0.00001], 'kernel': ['rbf']},\n",
    "              {'C': [0.1, 40, 100, 400], 'kernel': ['linear'], 'gamma': [0.001, 0.0001, 0.00001]},\n",
    "              {'C': [0.1, 40, 100, 400], 'kernel': ['poly'], 'gamma': [0.001, 0.0001, 0.00001],},]\n",
    "\n",
    "gs=GridSearchCV(clf6,param_grid).fit(X_train_PCA,y_train)\n",
    "gs.best_estimator_, gs.best_score_, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red4=PCA()\n",
    "sc2=StandardScaler()\n",
    "X_train_sc=sc2.fit_transform(X_train)\n",
    "X_test_sc=sc2.transform(X_test)\n",
    "X_train_PCA=red4.fit_transform(X_train_sc)\n",
    "X_test_PCA=red4.transform(X_test_sc)\n",
    "\n",
    "clf6=LinearSVC(max_iter=5000)\n",
    "param_grid = [{'C': [0.1, 40, 100, 400], 'penalty': ['l2'], 'loss': ['hinge','squared_hinge']},]\n",
    "gs=GridSearchCV(clf6,param_grid).fit(X_train_PCA,y_train)\n",
    "gs.best_estimator_, gs.best_score_, gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset_new_features.csv\")\n",
    "y=dataset.iloc[:,-1]\n",
    "X=dataset.iloc[:,:-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.575"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble1=RandomForestClassifier().fit(X_train, y_train)\n",
    "ensemble1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666666666666667"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble2=AdaBoostClassifier().fit(X_train, y_train)\n",
    "ensemble2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble3=GradientBoostingClassifier().fit(X_train, y_train)\n",
    "ensemble3.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "red4=PCA(0.95)\n",
    "X_train_PCA=red4.fit_transform(X_train)\n",
    "X_test_PCA=red4.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble1=RandomForestClassifier().fit(X_train_PCA, y_train)\n",
    "ensemble1.score(X_test_PCA, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48333333333333334"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble2=AdaBoostClassifier().fit(X_train_PCA, y_train)\n",
    "ensemble2.score(X_test_PCA, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333333333333333"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble3=GradientBoostingClassifier().fit(X_train_PCA, y_train)\n",
    "ensemble3.score(X_test_PCA,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset_new_features.csv\")\n",
    "y=dataset.iloc[:,-1]\n",
    "X=dataset.iloc[:,:-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(learning_rate=0.001, n_estimators=10000, num_leaves=25),\n",
       " 0.3608251353618546,\n",
       " 0,\n",
       " {'learning_rate': 0.001, 'n_estimators': 10000, 'num_leaves': 25})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble4 = lgb.LGBMClassifier()\n",
    "param_grid = {\n",
    "    'num_leaves': [25,28,31,33,35],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "    'n_estimators': [10000] #max\n",
    "}\n",
    "gbm = GridSearchCV(ensemble4, param_grid, cv=3)\n",
    "gbm.fit(X_train, y_train)\n",
    "gbm.best_estimator_, gbm.best_score_, gbm.best_index_, gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(learning_rate=0.01, num_leaves=21),\n",
       " 0.4716312056737588,\n",
       " 0,\n",
       " {'learning_rate': 0.01, 'n_estimators': 100, 'num_leaves': 21})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble5 = lgb.LGBMClassifier()\n",
    "param_grid = {\n",
    "    'num_leaves': [21,22,23,24,25,26],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100]\n",
    "}\n",
    "gbm2 = GridSearchCV(ensemble5, param_grid, cv=3)\n",
    "gbm2.fit(X_train, y_train)\n",
    "gbm2.best_estimator_, gbm2.best_score_, gbm2.best_index_, gbm2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_error: 0.7\tvalid_0's multi_logloss: 1.39241\n",
      "Training until validation scores don't improve for 70 rounds\n",
      "[2]\tvalid_0's multi_error: 0.7\tvalid_0's multi_logloss: 1.38761\n",
      "[3]\tvalid_0's multi_error: 0.7\tvalid_0's multi_logloss: 1.38294\n",
      "[4]\tvalid_0's multi_error: 0.7\tvalid_0's multi_logloss: 1.37834\n",
      "[5]\tvalid_0's multi_error: 0.708333\tvalid_0's multi_logloss: 1.37416\n",
      "[6]\tvalid_0's multi_error: 0.691667\tvalid_0's multi_logloss: 1.36986\n",
      "[7]\tvalid_0's multi_error: 0.675\tvalid_0's multi_logloss: 1.36586\n",
      "[8]\tvalid_0's multi_error: 0.666667\tvalid_0's multi_logloss: 1.362\n",
      "[9]\tvalid_0's multi_error: 0.658333\tvalid_0's multi_logloss: 1.35846\n",
      "[10]\tvalid_0's multi_error: 0.65\tvalid_0's multi_logloss: 1.35499\n",
      "[11]\tvalid_0's multi_error: 0.591667\tvalid_0's multi_logloss: 1.35103\n",
      "[12]\tvalid_0's multi_error: 0.575\tvalid_0's multi_logloss: 1.34762\n",
      "[13]\tvalid_0's multi_error: 0.575\tvalid_0's multi_logloss: 1.34414\n",
      "[14]\tvalid_0's multi_error: 0.566667\tvalid_0's multi_logloss: 1.34085\n",
      "[15]\tvalid_0's multi_error: 0.541667\tvalid_0's multi_logloss: 1.3378\n",
      "[16]\tvalid_0's multi_error: 0.541667\tvalid_0's multi_logloss: 1.33481\n",
      "[17]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.33127\n",
      "[18]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.32841\n",
      "[19]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.32569\n",
      "[20]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.32281\n",
      "[21]\tvalid_0's multi_error: 0.575\tvalid_0's multi_logloss: 1.32026\n",
      "[22]\tvalid_0's multi_error: 0.575\tvalid_0's multi_logloss: 1.31732\n",
      "[23]\tvalid_0's multi_error: 0.566667\tvalid_0's multi_logloss: 1.31419\n",
      "[24]\tvalid_0's multi_error: 0.566667\tvalid_0's multi_logloss: 1.31157\n",
      "[25]\tvalid_0's multi_error: 0.566667\tvalid_0's multi_logloss: 1.30873\n",
      "[26]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.30597\n",
      "[27]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.30332\n",
      "[28]\tvalid_0's multi_error: 0.566667\tvalid_0's multi_logloss: 1.30088\n",
      "[29]\tvalid_0's multi_error: 0.566667\tvalid_0's multi_logloss: 1.29837\n",
      "[30]\tvalid_0's multi_error: 0.575\tvalid_0's multi_logloss: 1.29613\n",
      "[31]\tvalid_0's multi_error: 0.583333\tvalid_0's multi_logloss: 1.29428\n",
      "[32]\tvalid_0's multi_error: 0.583333\tvalid_0's multi_logloss: 1.292\n",
      "[33]\tvalid_0's multi_error: 0.583333\tvalid_0's multi_logloss: 1.29032\n",
      "[34]\tvalid_0's multi_error: 0.583333\tvalid_0's multi_logloss: 1.28858\n",
      "[35]\tvalid_0's multi_error: 0.583333\tvalid_0's multi_logloss: 1.28651\n",
      "[36]\tvalid_0's multi_error: 0.575\tvalid_0's multi_logloss: 1.28461\n",
      "[37]\tvalid_0's multi_error: 0.575\tvalid_0's multi_logloss: 1.28243\n",
      "[38]\tvalid_0's multi_error: 0.575\tvalid_0's multi_logloss: 1.28088\n",
      "[39]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.27909\n",
      "[40]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.27781\n",
      "[41]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.27626\n",
      "[42]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.27483\n",
      "[43]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.27267\n",
      "[44]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.27162\n",
      "[45]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.2703\n",
      "[46]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.26877\n",
      "[47]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.26695\n",
      "[48]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.26589\n",
      "[49]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.26447\n",
      "[50]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.26315\n",
      "[51]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.26126\n",
      "[52]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.25998\n",
      "[53]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.25864\n",
      "[54]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.25726\n",
      "[55]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.2563\n",
      "[56]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.25424\n",
      "[57]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.253\n",
      "[58]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.25148\n",
      "[59]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.25001\n",
      "[60]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.24859\n",
      "[61]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.24713\n",
      "[62]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.24539\n",
      "[63]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.24444\n",
      "[64]\tvalid_0's multi_error: 0.566667\tvalid_0's multi_logloss: 1.24271\n",
      "[65]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.24149\n",
      "[66]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.23977\n",
      "[67]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.23907\n",
      "[68]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.23745\n",
      "[69]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.23626\n",
      "[70]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.23514\n",
      "[71]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.23394\n",
      "[72]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.23364\n",
      "[73]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.2322\n",
      "[74]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.23173\n",
      "[75]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.23061\n",
      "[76]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.22983\n",
      "[77]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.22952\n",
      "[78]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.22875\n",
      "[79]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.2281\n",
      "[80]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.22742\n",
      "[81]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.22625\n",
      "[82]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.22555\n",
      "[83]\tvalid_0's multi_error: 0.558333\tvalid_0's multi_logloss: 1.2253\n",
      "[84]\tvalid_0's multi_error: 0.55\tvalid_0's multi_logloss: 1.22416\n",
      "[85]\tvalid_0's multi_error: 0.541667\tvalid_0's multi_logloss: 1.22358\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_error: 0.541667\tvalid_0's multi_logloss: 1.3378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4583333333333333"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMClassifier(num_leaves=,\n",
    "                        learning_rate=0.0001,\n",
    "                        n_estimators=2000,\n",
    "                        max_depth=7)\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=['multi_error','multiclass'],\n",
    "        early_stopping_rounds=70)\n",
    "gbm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(learning_rate=0.01, max_depth=4, num_leaves=40),\n",
       " 0.4356363913673454,\n",
       " 8,\n",
       " {'learning_rate': 0.01,\n",
       "  'max_depth': 4,\n",
       "  'n_estimators': 100,\n",
       "  'num_leaves': 40})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red4=PCA(.95)\n",
    "X_train_PCA=red4.fit_transform(X_train)\n",
    "X_test_PCA=red4.transform(X_test)\n",
    "ensemble6 = lgb.LGBMClassifier()\n",
    "param_grid = {\n",
    "    'num_leaves': [40,38,37,34,32,30,28,25],\n",
    "    'learning_rate': [0.01,0.001],\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3,4,5,6,7,8,9,10]\n",
    "}\n",
    "gbm3 = GridSearchCV(ensemble6, param_grid, cv=3)\n",
    "gbm3.fit(X_train_PCA, y_train)\n",
    "gbm3.best_estimator_, gbm3.best_score_, gbm3.best_index_, gbm3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39166666666666666"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb1=GaussianNB().fit(X_train, y_train)\n",
    "nb1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.475"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb2=ComplementNB().fit(X_train, y_train)\n",
    "nb2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb4=BernoulliNB(alpha=0.075, binarize=0, fit_prior=True).fit(X_train, y_train)\n",
    "nb4.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4083333333333333"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6 = NearestCentroid().fit(X_train, y_train)\n",
    "clf6.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "red4=PCA(.95)\n",
    "X_train_PCA=red4.fit_transform(X_train)\n",
    "X_test_PCA=red4.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39166666666666666"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb1=GaussianNB().fit(X_train, y_train)\n",
    "nb1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.475"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb2=ComplementNB().fit(X_train, y_train)\n",
    "nb2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb4=BernoulliNB(alpha=0.075, binarize=0, fit_prior=True).fit(X_train, y_train)\n",
    "nb4.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4083333333333333"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6 = NearestCentroid().fit(X_train, y_train)\n",
    "clf6.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Couldn't run this test in some computers...\n",
    "\n",
    "#nca = NeighborhoodComponentsAnalysis().fit_transform(X_train, y_train) \n",
    "#nca.transform(X_test,y_test)\n",
    "#knn = KNeighborsClassifier(n_neighbors=7).fit(X_train, y_train)\n",
    "#knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: FFT (fast fourier transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 12002)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fourier=fft(X[0:12000])\n",
    "X_fourier_abs=np.abs(X_fourier)\n",
    "X_fourier=pd.DataFrame.from_records(X_fourier_abs)\n",
    "X_f=pd.concat([X_fourier, X[\"threshold_pas\"], X[\"peak_number\"]], axis=1, sort=False)\n",
    "X_fourier.shape\n",
    "#from here X_train X_test... Are fourier transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_f, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_fft= LogisticRegression(random_state=0, penalty='none').fit(X_train, y_train)\n",
    "clf_fft.score(X_test, y_test)\n",
    "clf_fft.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4575, {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}, SVC(C=1, gamma=0.0001), 5)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2_fft = SVC()\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "gs_fft=GridSearchCV(clf2_fft,param_grid).fit(X,y)\n",
    "gs_fft.cv_results_\n",
    "gs_fft.best_score_, gs_fft.best_params_, gs_fft.best_estimator_, gs_fft.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3_fft = LinearSVC()\n",
    "param_grid = [{'C': [0.5, 1, 10, 100, 1000], 'loss': ['hinge', 'squared_hinge']},]\n",
    "gs2_fft=GridSearchCV(clf3,param_grid).fit(X,y)\n",
    "gs2_fft.best_score_, gs2_fft.best_params_, gs2_fft.best_estimator_, gs2_fft.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6166666666666667 1\n"
     ]
    }
   ],
   "source": [
    "#KNC n_neighbors iterators to test the best number of it\n",
    "sc=0\n",
    "iteration=0\n",
    "for neig in range(1,200):\n",
    "    clf3 = KNeighborsClassifier(n_neighbors=neig).fit(X_train, y_train)\n",
    "    if sc<clf3.score(X_test,y_test):\n",
    "        sc=clf3.score(X_test,y_test)\n",
    "        iteration=neig\n",
    "print (sc, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775 2\n"
     ]
    }
   ],
   "source": [
    "red5=PCA(.90)\n",
    "X_train_PCA=red5.fit_transform(X_train)\n",
    "X_test_PCA=red5.transform(X_test)\n",
    "sc=0\n",
    "iteration=0\n",
    "for neig in range(1,200):\n",
    "    clf3 = KNeighborsClassifier(n_neighbors=neig).fit(X_train_PCA, y_train)\n",
    "    if sc<clf3.score(X_test_PCA,y_test):\n",
    "        sc=clf3.score(X_test_PCA,y_test)\n",
    "        iteration=neig\n",
    "print (sc, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6166666666666667"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_kn_fft= KNeighborsClassifier(iteration).fit(X_train, y_train)\n",
    "clf_kn_fft.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21666666666666667"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb4=BernoulliNB(alpha=1).fit(X_train, y_train)\n",
    "nb4.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7607142857142857,\n",
       " LogisticRegression(random_state=0, solver='liblinear'),\n",
       " {'penalty': 'l2', 'solver': 'liblinear'})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4_fft = LogisticRegression(random_state=0)\n",
    "params=([{'penalty': ['none'], 'solver': ['newton-cg', 'lbfgs', 'sag','saga']},\n",
    "        {'penalty': ['elasticnet'], 'solver': ['saga']},\n",
    "        {'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'sag','saga','liblinear']},\n",
    "        {'penalty': ['l1'], 'solver': ['liblinear', 'saga']},])\n",
    "\n",
    "gs=GridSearchCV(clf4_fft,params).fit(X_train,y_train)\n",
    "gs.best_score_, gs.best_estimator_, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8416666666666667"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5_fft=LogisticRegression(penalty='none', solver='sag', max_iter=10000).fit(X_train, y_train)\n",
    "clf5_fft.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8178571428571428,\n",
       " LogisticRegression(C=100, max_iter=10000, penalty='l1', random_state=0,\n",
       "                    solver='liblinear'),\n",
       " {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6_fft = LogisticRegression(random_state=0, max_iter=10000)\n",
    "params=([{'penalty': ['none'], 'solver': ['newton-cg', 'lbfgs', 'sag','saga']},\n",
    "        {'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'sag','saga','liblinear'], 'C': [0.1, 1, 100]},\n",
    "        {'penalty': ['l1'], 'solver': ['liblinear', 'saga'], 'C': [0.1, 1, 100]},])\n",
    "\n",
    "gs=GridSearchCV(clf6_fft,params).fit(X_train,y_train)\n",
    "gs.best_score_, gs.best_estimator_, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6_fft_b=LogisticRegression(random_state=0, max_iter=10000, C=150, penalty'l1', solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8416666666666667, 0.8333333333333334)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7_fft=LogisticRegression(random_state=0, max_iter=10000, penalty='none', solver='sag', multi_class='multinomial').fit(X_train, y_train)\n",
    "clf8_fft=LogisticRegression(random_state=0, max_iter=10000, penalty='none', solver='sag', multi_class='ovr').fit(X_train, y_train)\n",
    "clf7_fft.score(X_test, y_test), clf8_fft.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7821428571428573,\n",
       " LogisticRegression(l1_ratio=0, max_iter=10000, multi_class='ovr',\n",
       "                    penalty='elasticnet', random_state=0, solver='saga'),\n",
       " {'l1_ratio': 0, 'multi_class': 'ovr'})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf10_fft=LogisticRegression(random_state=0, max_iter=10000, penalty='elasticnet', solver='saga')\n",
    "params=([{'multi_class': ['ovr', 'multinomial'], 'l1_ratio':[0, 0.25, 0.5, 0.75, 1]}])\n",
    "gs=GridSearchCV(clf10_fft,params).fit(X_train,y_train)\n",
    "gs.best_score_, gs.best_estimator_, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7583333333333333"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red4=PCA(.95)\n",
    "X_train_PCA=red4.fit_transform(X_train)\n",
    "X_test_PCA=red4.transform(X_test)\n",
    "clf8_fft=LogisticRegression(random_state=0, max_iter=10000, penalty='none', solver='sag', multi_class='ovr').fit(X_train_PCA, y_train)\n",
    "clf8_fft.score(X_test_PCA, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7464285714285714,\n",
       " LogisticRegression(max_iter=10000, penalty='none', random_state=0, solver='sag'),\n",
       " {'penalty': 'none', 'solver': 'sag'})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf11_fft_PCA = LogisticRegression(random_state=0, max_iter=10000)\n",
    "params=([{'penalty': ['none'], 'solver': ['newton-cg', 'lbfgs', 'sag','saga']},\n",
    "        {'penalty': ['l2'], 'solver': ['newton-cg', 'sag','saga','liblinear'], 'C': [0.1, 1, 100]},\n",
    "        {'penalty': ['l1'], 'solver': ['liblinear', 'saga'], 'C': [0.1, 1, 100]},])\n",
    "\n",
    "gs=GridSearchCV(clf11_fft_PCA,params).fit(X_train_PCA,y_train)\n",
    "gs.best_score_, gs.best_estimator_, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_fft= lgb.LGBMClassifier()\n",
    "param_grid = {\n",
    "    'num_leaves': [25,28,31,33,35],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "    'n_estimators': [10000] #max\n",
    "}\n",
    "gbm = GridSearchCV(lgbm_fft, param_grid, cv=3)\n",
    "gbm.fit(X_train, y_train)\n",
    "gbm.best_estimator_, gbm.best_score_, gbm.best_index_, gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red4=PCA(.95)\n",
    "X_train_PCA=red4.fit_transform(X_train)\n",
    "X_test_PCA=red4.transform(X_test)\n",
    "\n",
    "lgbm_fft_PCA= lgb.LGBMClassifier()\n",
    "param_grid = {\n",
    "    'num_leaves': [25,28,31,33,35],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "    'n_estimators': [10000] #max\n",
    "}\n",
    "gbm = GridSearchCV(lgbm_fft_PCA, param_grid)\n",
    "gbm.fit(X_train_PCA, y_train)\n",
    "gbm.best_estimator_, gbm.best_score_, gbm.best_index_, gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red4=PCA(.95)\n",
    "X_train_PCA=red4.fit_transform(X_train)\n",
    "X_test_PCA=red4.transform(X_test)\n",
    "\n",
    "gbm = lgb.LGBMClassifier(num_leaves=15,\n",
    "                        learning_rate=0.001,\n",
    "                        n_estimators=20000)#                        max_depth=10)             \n",
    "gbm.fit(X_train_PCA, y_train,\n",
    "eval_set=[(X_test_PCA, y_test)],\n",
    "eval_metric=['multi_error','multiclass'],\n",
    "early_stopping_rounds=100)\n",
    "\n",
    "\n",
    "gbm.score(X_test_PCA, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
