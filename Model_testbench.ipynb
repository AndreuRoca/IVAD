{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA, KernelPCA, IncrementalPCA\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset_clone.csv\")\n",
    "y=dataset.iloc[:,-1]\n",
    "X=dataset.iloc[:,:-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, penalty='none').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3082706766917293"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2=LinearSVC(penalty='l2',random_state=0, tol=1e-5,max_iter=9000,C=1,loss='squared_hinge').fit(X_train,y_train)\n",
    "#clf2 = make_pipeline(StandardScaler(),LinearSVC(penalty='l2',random_state=0, tol=1e-5,max_iter=9000,C=1,loss='squared_hinge')).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3308270676691729, 1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.score(X_test, y_test), clf2.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = KNeighborsClassifier(n_neighbors=199).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22556390977443608"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = SVC(random_state=1, kernel='rbf', C=80, gamma=0.0001).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40601503759398494"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "gs=GridSearchCV(clf3,param_grid).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([3.22590981, 2.90486374, 2.90879188, 3.14414272, 3.1916008 ,\n",
       "        3.01643968, 3.20180283, 3.05305429, 3.19754109, 3.06712198,\n",
       "        3.20482917, 3.05680599]),\n",
       " 'std_fit_time': array([0.17841639, 0.00599297, 0.06740299, 0.48446613, 0.17261358,\n",
       "        0.09387891, 0.17127592, 0.11273523, 0.17818782, 0.11086474,\n",
       "        0.1749167 , 0.11442708]),\n",
       " 'mean_score_time': array([0.54430785, 0.50200553, 0.56045299, 0.50750308, 0.50728784,\n",
       "        0.50748372, 0.5088213 , 0.5071557 , 0.50738134, 0.50971842,\n",
       "        0.50737395, 0.50945802]),\n",
       " 'std_score_time': array([0.04003115, 0.00629903, 0.10834059, 0.01663082, 0.00454766,\n",
       "        0.00358675, 0.00242535, 0.00164854, 0.00118989, 0.00347222,\n",
       "        0.00183559, 0.00658875]),\n",
       " 'param_C': masked_array(data=[1, 10, 100, 1000, 1, 1, 10, 10, 100, 100, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'linear', 'linear', 'linear', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[--, --, --, --, 0.001, 0.0001, 0.001, 0.0001, 0.001,\n",
       "                    0.0001, 0.001, 0.0001],\n",
       "              mask=[ True,  True,  True,  True, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 100, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.31460674, 0.31460674, 0.31460674, 0.31460674, 0.29213483,\n",
       "        0.35955056, 0.29213483, 0.40449438, 0.29213483, 0.39325843,\n",
       "        0.29213483, 0.39325843]),\n",
       " 'split1_test_score': array([0.27272727, 0.27272727, 0.27272727, 0.27272727, 0.19318182,\n",
       "        0.34090909, 0.20454545, 0.42045455, 0.20454545, 0.43181818,\n",
       "        0.20454545, 0.43181818]),\n",
       " 'split2_test_score': array([0.26136364, 0.26136364, 0.26136364, 0.26136364, 0.125     ,\n",
       "        0.32954545, 0.17045455, 0.32954545, 0.17045455, 0.31818182,\n",
       "        0.17045455, 0.31818182]),\n",
       " 'split3_test_score': array([0.34090909, 0.34090909, 0.34090909, 0.34090909, 0.28409091,\n",
       "        0.42045455, 0.28409091, 0.46590909, 0.28409091, 0.5       ,\n",
       "        0.28409091, 0.5       ]),\n",
       " 'split4_test_score': array([0.39772727, 0.39772727, 0.39772727, 0.39772727, 0.28409091,\n",
       "        0.47727273, 0.28409091, 0.40909091, 0.28409091, 0.40909091,\n",
       "        0.28409091, 0.40909091]),\n",
       " 'mean_test_score': array([0.3174668 , 0.3174668 , 0.3174668 , 0.3174668 , 0.23569969,\n",
       "        0.38554648, 0.24706333, 0.40589888, 0.24706333, 0.41046987,\n",
       "        0.24706333, 0.41046987]),\n",
       " 'std_test_score': array([0.0492923 , 0.0492923 , 0.0492923 , 0.0492923 , 0.06622769,\n",
       "        0.0555638 , 0.0499003 , 0.04394337, 0.0499003 , 0.058799  ,\n",
       "        0.0499003 , 0.058799  ]),\n",
       " 'rank_test_score': array([ 5,  5,  5,  5, 12,  4,  9,  3,  9,  1,  9,  1], dtype=int32)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SVC(C=100, gamma=0.0001, random_state=1),\n",
       " {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_,gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([3.28216395, 3.26196895, 4.42452836, 4.13522758, 3.0548821 ,\n",
       "        3.48752589, 3.68803492, 3.81658397, 3.64238634]),\n",
       " 'std_fit_time': array([0.18895024, 0.32531112, 1.14137695, 0.68690801, 0.1154186 ,\n",
       "        0.92989758, 0.51116434, 0.32242091, 0.28673085]),\n",
       " 'mean_score_time': array([0.50749831, 0.60030479, 0.69078894, 0.55778871, 0.51039839,\n",
       "        0.59986639, 0.55756497, 0.64523478, 0.60189142]),\n",
       " 'std_score_time': array([0.00134268, 0.11016675, 0.1272967 , 0.09428228, 0.00374328,\n",
       "        0.12306794, 0.02960839, 0.07219875, 0.08498597]),\n",
       " 'param_C': masked_array(data=[40, 40, 40, 100, 100, 100, 400, 400, 400],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.001, 0.0001, 1e-05, 0.001, 0.0001, 1e-05, 0.001,\n",
       "                    0.0001, 1e-05],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 40, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 40, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 40, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       "  {'C': 400, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 400, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 400, 'gamma': 1e-05, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.29213483, 0.39325843, 0.40449438, 0.29213483, 0.39325843,\n",
       "        0.40449438, 0.29213483, 0.39325843, 0.40449438]),\n",
       " 'split1_test_score': array([0.20454545, 0.42045455, 0.42045455, 0.20454545, 0.43181818,\n",
       "        0.40909091, 0.20454545, 0.43181818, 0.36363636]),\n",
       " 'split2_test_score': array([0.17045455, 0.31818182, 0.30681818, 0.17045455, 0.31818182,\n",
       "        0.30681818, 0.17045455, 0.31818182, 0.31818182]),\n",
       " 'split3_test_score': array([0.28409091, 0.5       , 0.38636364, 0.28409091, 0.5       ,\n",
       "        0.43181818, 0.28409091, 0.5       , 0.44318182]),\n",
       " 'split4_test_score': array([0.28409091, 0.40909091, 0.46590909, 0.28409091, 0.40909091,\n",
       "        0.44318182, 0.28409091, 0.40909091, 0.42045455]),\n",
       " 'mean_test_score': array([0.24706333, 0.40819714, 0.39680797, 0.24706333, 0.41046987,\n",
       "        0.39908069, 0.24706333, 0.41046987, 0.38998979]),\n",
       " 'std_test_score': array([0.0499003 , 0.0581459 , 0.05215449, 0.0499003 , 0.058799  ,\n",
       "        0.04828775, 0.0499003 , 0.058799  , 0.04431425]),\n",
       " 'rank_test_score': array([7, 3, 5, 7, 1, 4, 7, 1, 6], dtype=int32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "  {'C': [40,100,400], 'gamma': [0.001, 0.0001, 0.00001], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "gs=GridSearchCV(clf3,param_grid).fit(X,y)\n",
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SVC(C=100, gamma=0.0001, random_state=1),\n",
       " {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       " 0.41046986721144024)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_, gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "param_grid2= [\n",
    "  {'C': [1,10,80,100,400,1000], 'loss': ['hinge','squared_hinge']},]\n",
    "gs2=GridSearchCV(LinearSVC(), param_grid2).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34466292134831467"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "red=PCA(n_components=441)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t=red.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48872180451127817"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y, test_size=0.30)\n",
    "clf3 = SVC(random_state=1, kernel='rbf', C=80, gamma=0.0001).fit(X_train,y_train)\n",
    "clf3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(C=100, gamma=0.0001, random_state=1), 0.41046986721144024)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red2=KernelPCA()\n",
    "X_t=red.fit_transform(X)\n",
    "\n",
    "param_grid = [{'C': [40,100,400], 'gamma': [0.001, 0.0001, 0.00001], 'kernel': ['rbf']},]\n",
    "gs=GridSearchCV(clf3,param_grid).fit(X_t,y)\n",
    "gs.best_estimator_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(C=100, gamma=0.0001),\n",
       " 0.41046986721144024,\n",
       " {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red2=IncrementalPCA()\n",
    "X_t=red.fit_transform(X)\n",
    "clf4=SVC()\n",
    "param_grid = [{'C': [40,100,400], 'gamma': [0.001, 0.0001, 0.00001], 'kernel': ['rbf']},\n",
    "              {'C': [40, 100, 400], 'kernel': ['linear'], 'gamma': [0.001, 0.0001, 0.00001]},\n",
    "              {'C': [40, 100, 400], 'kernel': ['poly'], 'gamma': [0.001, 0.0001, 0.00001],},]\n",
    "\n",
    "gs=GridSearchCV(clf4,param_grid).fit(X_t,y)\n",
    "gs.best_estimator_, gs.best_score_, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(C=100, gamma=0.0001),\n",
       " 0.41046986721144024,\n",
       " {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red3=KernelPCA()\n",
    "X_t=red.fit_transform(X)\n",
    "clf5=SVC()\n",
    "param_grid = [{'C': [40,100,400], 'gamma': [0.001, 0.0001, 0.00001], 'kernel': ['rbf']},\n",
    "              {'C': [40, 100, 400], 'kernel': ['linear'], 'gamma': [0.001, 0.0001, 0.00001]},\n",
    "              {'C': [40, 100, 400], 'kernel': ['poly'], 'gamma': [0.001, 0.0001, 0.00001],},]\n",
    "\n",
    "gs=GridSearchCV(clf5,param_grid).fit(X_t,y)\n",
    "gs.best_estimator_, gs.best_score_, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(C=100, gamma=0.0001),\n",
       " 0.41046986721144024,\n",
       " {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red4=PCA()\n",
    "X_t=red.fit_transform(X)\n",
    "sc=StandardScaler()\n",
    "sc.fit_transform(X_t)\n",
    "clf6=SVC()\n",
    "param_grid = [{'C': [0.1, 40, 100, 400], 'gamma': [0.001, 0.0001, 0.00001], 'kernel': ['rbf']},\n",
    "              {'C': [0.1, 40, 100, 400], 'kernel': ['linear'], 'gamma': [0.001, 0.0001, 0.00001]},\n",
    "              {'C': [0.1, 40, 100, 400], 'kernel': ['poly'], 'gamma': [0.001, 0.0001, 0.00001],},]\n",
    "\n",
    "gs=GridSearchCV(clf6,param_grid).fit(X_t,y)\n",
    "gs.best_estimator_, gs.best_score_, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual='False'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "red4=PCA()\n",
    "X_t=red.fit_transform(X)\n",
    "sc=StandardScaler()\n",
    "sc.fit_transform(X_t)\n",
    "clf6=LinearSVC(max_iter=5000)\n",
    "param_grid = [{'C': [0.1, 40, 100, 400], 'penalty': ['l2'], 'loss': ['hinge','squared_hinge']},\n",
    "              {'C': [0.1, 40, 100, 400], 'penalty': ['l1'], 'loss': ['hinge'], 'dual': ['False']},]\n",
    "gs=GridSearchCV(clf6,param_grid).fit(X_t,y)\n",
    "gs.best_estimator_, gs.best_score_, gs.best_params_\n",
    "\n",
    "clf2=LinearSVC(penalty='l2',random_state=0, tol=1e-5,max_iter=9000,C=1,loss='squared_hinge').fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47368421052631576"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble1=RandomForestClassifier().fit(X_train, y_train)\n",
    "ensemble1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37593984962406013"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble2=AdaBoostClassifier().fit(X_train, y_train)\n",
    "ensemble2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41353383458646614"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble3=GradientBoostingClassifier().fit(X_train, y_train)\n",
    "ensemble3.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LGBMClassifier(),\n",
       "             param_grid={'learning_rate': [0.001, 0.01, 0.1, 1],\n",
       "                         'n_estimators': [10, 100, 1000, 10000],\n",
       "                         'num_leaves': [25, 28, 31, 33, 35]})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble4 = lgb.LGBMClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'num_leaves': [25,28,31,33,35],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "    'n_estimators': [10, 100, 1000, 10000]\n",
    "}\n",
    "\n",
    "gbm = GridSearchCV(ensemble4, param_grid, cv=3)\n",
    "gbm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(learning_rate=0.01, num_leaves=25),\n",
       " 0.4254394314360048,\n",
       " 25,\n",
       " {'learning_rate': 0.01, 'n_estimators': 100, 'num_leaves': 25})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.best_estimator_, gbm.best_score_, gbm.best_index_, gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LGBMClassifier(),\n",
       "             param_grid={'learning_rate': [0.01, 0.1], 'n_estimators': [100],\n",
       "                         'num_leaves': [21, 22, 23, 24, 25, 26]})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble5 = lgb.LGBMClassifier()\n",
    "param_grid = {\n",
    "    'num_leaves': [21,22,23,24,25,26],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100]\n",
    "}\n",
    "gbm2 = GridSearchCV(ensemble5, param_grid, cv=3)\n",
    "gbm2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(learning_rate=0.01, num_leaves=21),\n",
       " 0.4254394314360048,\n",
       " 0,\n",
       " {'learning_rate': 0.01, 'n_estimators': 100, 'num_leaves': 21})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm2.best_estimator_, gbm2.best_score_, gbm2.best_index_, gbm2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_error: 0.699248\tvalid_0's multi_logloss: 1.38216\n",
      "Training until validation scores don't improve for 70 rounds\n",
      "[2]\tvalid_0's multi_error: 0.699248\tvalid_0's multi_logloss: 1.3801\n",
      "[3]\tvalid_0's multi_error: 0.699248\tvalid_0's multi_logloss: 1.3778\n",
      "[4]\tvalid_0's multi_error: 0.699248\tvalid_0's multi_logloss: 1.37606\n",
      "[5]\tvalid_0's multi_error: 0.699248\tvalid_0's multi_logloss: 1.37427\n",
      "[6]\tvalid_0's multi_error: 0.676692\tvalid_0's multi_logloss: 1.37198\n",
      "[7]\tvalid_0's multi_error: 0.676692\tvalid_0's multi_logloss: 1.36998\n",
      "[8]\tvalid_0's multi_error: 0.654135\tvalid_0's multi_logloss: 1.36865\n",
      "[9]\tvalid_0's multi_error: 0.669173\tvalid_0's multi_logloss: 1.36674\n",
      "[10]\tvalid_0's multi_error: 0.654135\tvalid_0's multi_logloss: 1.36598\n",
      "[11]\tvalid_0's multi_error: 0.669173\tvalid_0's multi_logloss: 1.36409\n",
      "[12]\tvalid_0's multi_error: 0.676692\tvalid_0's multi_logloss: 1.36255\n",
      "[13]\tvalid_0's multi_error: 0.661654\tvalid_0's multi_logloss: 1.36161\n",
      "[14]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.35972\n",
      "[15]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.35908\n",
      "[16]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.35845\n",
      "[17]\tvalid_0's multi_error: 0.661654\tvalid_0's multi_logloss: 1.35738\n",
      "[18]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.35585\n",
      "[19]\tvalid_0's multi_error: 0.654135\tvalid_0's multi_logloss: 1.35446\n",
      "[20]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.35309\n",
      "[21]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.3526\n",
      "[22]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.35088\n",
      "[23]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.34983\n",
      "[24]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.34801\n",
      "[25]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.34753\n",
      "[26]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.3462\n",
      "[27]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.34595\n",
      "[28]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.34473\n",
      "[29]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.34389\n",
      "[30]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.34335\n",
      "[31]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.34275\n",
      "[32]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.34161\n",
      "[33]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.34051\n",
      "[34]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.34071\n",
      "[35]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.33936\n",
      "[36]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.33898\n",
      "[37]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.33751\n",
      "[38]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.3375\n",
      "[39]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.33638\n",
      "[40]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.33627\n",
      "[41]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.33584\n",
      "[42]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.33465\n",
      "[43]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.33463\n",
      "[44]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.33375\n",
      "[45]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.33339\n",
      "[46]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.33299\n",
      "[47]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.33204\n",
      "[48]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.33169\n",
      "[49]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.33186\n",
      "[50]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.33071\n",
      "[51]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.3301\n",
      "[52]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.32988\n",
      "[53]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.3294\n",
      "[54]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.32881\n",
      "[55]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.32838\n",
      "[56]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.32783\n",
      "[57]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.32803\n",
      "[58]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.3275\n",
      "[59]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.32682\n",
      "[60]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.32673\n",
      "[61]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.32563\n",
      "[62]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.32498\n",
      "[63]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.32517\n",
      "[64]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.3242\n",
      "[65]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.32322\n",
      "[66]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.32296\n",
      "[67]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.3227\n",
      "[68]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.32172\n",
      "[69]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.32169\n",
      "[70]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.32149\n",
      "[71]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.32053\n",
      "[72]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.32014\n",
      "[73]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.32076\n",
      "[74]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.32101\n",
      "[75]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.31998\n",
      "[76]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.31928\n",
      "[77]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.31919\n",
      "[78]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.31934\n",
      "[79]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.31849\n",
      "[80]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31852\n",
      "[81]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.31809\n",
      "[82]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.31828\n",
      "[83]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31811\n",
      "[84]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31798\n",
      "[85]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31843\n",
      "[86]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31703\n",
      "[87]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31733\n",
      "[88]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31675\n",
      "[89]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.3173\n",
      "[90]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.31676\n",
      "[91]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.31609\n",
      "[92]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31538\n",
      "[93]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31455\n",
      "[94]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.31428\n",
      "[95]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.31492\n",
      "[96]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.31455\n",
      "[97]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.31364\n",
      "[98]\tvalid_0's multi_error: 0.609023\tvalid_0's multi_logloss: 1.31329\n",
      "[99]\tvalid_0's multi_error: 0.609023\tvalid_0's multi_logloss: 1.31264\n",
      "[100]\tvalid_0's multi_error: 0.609023\tvalid_0's multi_logloss: 1.31197\n",
      "[101]\tvalid_0's multi_error: 0.609023\tvalid_0's multi_logloss: 1.31166\n",
      "[102]\tvalid_0's multi_error: 0.609023\tvalid_0's multi_logloss: 1.31048\n",
      "[103]\tvalid_0's multi_error: 0.609023\tvalid_0's multi_logloss: 1.31094\n",
      "[104]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.31074\n",
      "[105]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.31003\n",
      "[106]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.30924\n",
      "[107]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.30891\n",
      "[108]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.30944\n",
      "[109]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.30935\n",
      "[110]\tvalid_0's multi_error: 0.609023\tvalid_0's multi_logloss: 1.30894\n",
      "[111]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.30901\n",
      "[112]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.30946\n",
      "[113]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.30844\n",
      "[114]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.30948\n",
      "[115]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.30929\n",
      "[116]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.30936\n",
      "[117]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31019\n",
      "[118]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31111\n",
      "[119]\tvalid_0's multi_error: 0.646617\tvalid_0's multi_logloss: 1.31185\n",
      "[120]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31233\n",
      "[122]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31182\n",
      "[123]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31242\n",
      "[124]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31263\n",
      "[125]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31306\n",
      "[126]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31391\n",
      "[127]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.3142\n",
      "[128]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31402\n",
      "[129]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31379\n",
      "[130]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31364\n",
      "[131]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31468\n",
      "[132]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31464\n",
      "[133]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31396\n",
      "[134]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31453\n",
      "[135]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31408\n",
      "[136]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31456\n",
      "[137]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31471\n",
      "[138]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31516\n",
      "[139]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31523\n",
      "[140]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.3156\n",
      "[141]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31559\n",
      "[142]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31604\n",
      "[143]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31592\n",
      "[144]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31599\n",
      "[145]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31634\n",
      "[146]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31716\n",
      "[147]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31637\n",
      "[148]\tvalid_0's multi_error: 0.639098\tvalid_0's multi_logloss: 1.31647\n",
      "[149]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31721\n",
      "[150]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31717\n",
      "[151]\tvalid_0's multi_error: 0.631579\tvalid_0's multi_logloss: 1.31748\n",
      "[152]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.31811\n",
      "[153]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31872\n",
      "[154]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31957\n",
      "[155]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31966\n",
      "[156]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31943\n",
      "[157]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31976\n",
      "[158]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31967\n",
      "[159]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.32015\n",
      "[160]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31969\n",
      "[161]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.31961\n",
      "[162]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.32105\n",
      "[163]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.32136\n",
      "[164]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.32219\n",
      "[165]\tvalid_0's multi_error: 0.62406\tvalid_0's multi_logloss: 1.32276\n",
      "[166]\tvalid_0's multi_error: 0.616541\tvalid_0's multi_logloss: 1.32266\n",
      "[167]\tvalid_0's multi_error: 0.609023\tvalid_0's multi_logloss: 1.32381\n",
      "[168]\tvalid_0's multi_error: 0.609023\tvalid_0's multi_logloss: 1.32394\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's multi_error: 0.609023\tvalid_0's multi_logloss: 1.31329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, max_depth=7, n_estimators=200, num_leaves=25)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMClassifier(num_leaves=25,\n",
    "                        learning_rate=0.01,\n",
    "                        n_estimators=200,\n",
    "                        max_depth=7)\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=['multi_error','multiclass'],\n",
    "        early_stopping_rounds=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LGBMClassifier(),\n",
       "             param_grid={'learning_rate': [0.01, 0.001],\n",
       "                         'max_depth': [7, 8, 9, 10], 'n_estimators': [100],\n",
       "                         'num_leaves': [22, 21, 20, 19, 18]})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble6 = lgb.LGBMClassifier()\n",
    "param_grid = {\n",
    "    'num_leaves': [22,21,20,19,18],\n",
    "    'learning_rate': [0.01,0.001],\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [7,8,9,10]\n",
    "}\n",
    "gbm3 = GridSearchCV(ensemble5, param_grid, cv=3)\n",
    "gbm3.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(learning_rate=0.01, max_depth=9, num_leaves=22),\n",
       " 0.4254394314360048,\n",
       " 10,\n",
       " {'learning_rate': 0.01,\n",
       "  'max_depth': 9,\n",
       "  'n_estimators': 100,\n",
       "  'num_leaves': 22})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm3.best_estimator_, gbm3.best_score_, gbm3.best_index_, gbm3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
